import requests
from bs4 import BeautifulSoup
import os

# å¾ GitHub Secrets è®€å– Webhook ç¶²å€
DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK")

def send_to_discord(title, link, prefix):
    """å°‡è¨Šæ¯ç™¼é€è‡³ Discord"""
    payload = {"content": f"{prefix} ã€{title}ã€‘\nğŸ”— {link}"}
    try:
        requests.post(DISCORD_WEBHOOK_URL, json=payload)
    except:
        pass

def fetch_and_filter(rss_url, prefix):
    """æŠ“å–ä¸¦é€²è¡ŒäºŒæ¬¡åš´æ ¼æª¢æŸ¥ï¼Œç¢ºä¿æ¨™é¡ŒçœŸçš„èˆ‡ç«ç½/çˆ†ç‚¸æœ‰é—œ"""
    try:
        res = requests.get(rss_url)
        # RSS æ˜¯ XML æ ¼å¼ï¼Œä½¿ç”¨ xml è§£æå™¨
        soup = BeautifulSoup(res.content, features="xml")
        
        # 1. èªå¯çš„ã€ŒçœŸç«è­¦ã€é—œéµå­—
        valid_keywords = ["ç«", "æ´©æ¼", "çˆ†ç‚¸", "æ°£çˆ†", "ç«è­¦", "ç«ç‡’", "ç„šæ¯€", "Fire", "Explosion"]
        
        # 2. æ’é™¤ã€Œå½¢å®¹è©ã€æˆ–ã€Œç„¡é—œã€é—œéµå­—
        # é¡å¤–åŠ å…¥ï¼šç§˜å¯†ã€éš±ç§ã€åå–® (é é˜²æ´©æ¼é¡èª¤å ±)
        exclude_keywords = [
            "è²·æ°£", "æ•ˆèƒ½", "ç¥¨æˆ¿", "ç†±åº¦", "è‚¡å¸‚", "é¸æƒ…", "åƒé¸", 
            "æ¨‚é€", "ç§˜å¯†", "éš±ç§", "åå–®", "å€‹è³‡","æ¨¡æ“¬"
        ]
        
        for item in soup.find_all('item')[:10]:
            title = item.title.text
            link = item.link.text
            
            # é‚è¼¯åˆ¤æ–·ï¼šåŒ…å«æœ‰æ•ˆå­—çœ¼ ä¸” ä¸åŒ…å«æ’é™¤å­—çœ¼
            has_valid = any(k.lower() in title.lower() for k in valid_keywords)
            has_exclude = any(e in title for e in exclude_keywords)
            
            if has_valid and not has_exclude:
                print(f"ç¬¦åˆæ¢ä»¶ä¸¦ç™¼é€ï¼š{title}")
                send_to_discord(title, link, prefix)
                
    except Exception as e:
        print(f"æŠ“å–å¤±æ•— ({prefix}): {e}")

if __name__ == "__main__":
    print("--- å•Ÿå‹•çµ‚æ¥µç²¾æº–ç›£æ¸¬ç³»çµ± ---")
    
    # 1. å°ç£æœ¬åœ°æœå°‹ (ä¸­æ–‡åª’é«”è¯æ’­)
    # hl=zh-TW, gl=TW ç¢ºä¿æŠ“åˆ°å°ç£å„å¤§å ±ç¤¾æ–°è
    tw_url = "https://news.google.com/rss/search?q=ç«ç½+OR+çˆ†ç‚¸+OR+ç«è­¦+when:1h&hl=zh-TW&gl=TW&ceid=TW:zh-tw"
    fetch_and_filter(tw_url, "ğŸ‡¹ğŸ‡¼ **å°ç£å³æ™‚ç«è­¦**")
    
    # 2. å…¨çƒè‹±æ–‡æœå°‹ (åœ‹éš›ç¬¬ä¸€æ‰‹æ¶ˆæ¯)
    # æ”¹å› hl=en-US ä»¥ç²å–ç¾åœ‹ã€æ­æ´²ã€æ—¥æœ¬ç­‰åœ°åŸæ–‡å ±å°ï¼Œé¿å…èˆ‡å°ç£æ–°èé‡è¤‡
    global_url = "https://news.google.com/rss/search?q=Fire+OR+Explosion+when:1h&hl=en-US&gl=US&ceid=US:en"
    fetch_and_filter(global_url, "ğŸŒ **å…¨çƒé‡å¤§è­¦å ±**")
    
    print("--- ç›£æ¸¬çµæŸ ---")
