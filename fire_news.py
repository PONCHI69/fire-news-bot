import requests
from bs4 import BeautifulSoup
import os

DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK")

def send_to_discord(title, link, prefix):
    payload = {"content": f"{prefix} ã€{title}ã€‘\nğŸ”— {link}"}
    try:
        requests.post(DISCORD_WEBHOOK_URL, json=payload)
    except:
        pass

def fetch_and_filter(rss_url, prefix):
    """æŠ“å–ä¸¦é€²è¡ŒäºŒæ¬¡åš´æ ¼æª¢æŸ¥ï¼Œç¢ºä¿æ¨™é¡ŒçœŸçš„èˆ‡ç«ç½/çˆ†ç‚¸æœ‰é—œ"""
    try:
        res = requests.get(rss_url)
        soup = BeautifulSoup(res.content, features="xml")
        
        # é€™æ˜¯æˆ‘å€‘èªå¯çš„ã€ŒçœŸç«è­¦ã€é—œéµå­—
        valid_keywords = ["ç«","æ´©æ¼", "çˆ†ç‚¸", "æ°£çˆ†", "ç«è­¦", "ç«ç‡’", "ç„šæ¯€", "Fire", "Explosion"]
        # é€™æ˜¯æˆ‘å€‘è¦æ’é™¤çš„ã€Œç„¡é—œã€é—œéµå­—ï¼ˆä¾‹å¦‚ï¼šè²·æ°£çˆ†ç‚¸ã€æ•ˆèƒ½çˆ†ç‚¸ï¼‰
        exclude_keywords = ["è²·æ°£", "æ•ˆèƒ½", "ç¥¨æˆ¿", "ç†±åº¦", "è‚¡å¸‚"]
        
        for item in soup.find_all('item')[:10]:
            title = item.title.text
            link = item.link.text
            
            # é‚è¼¯ï¼šå¿…é ˆåŒ…å« valid ä¸­çš„å­—ï¼Œä¸”ä¸èƒ½åŒ…å« exclude ä¸­çš„å­—
            has_valid = any(k.lower() in title.lower() for k in valid_keywords)
            has_exclude = any(e in title for e in exclude_keywords)
            
            if has_valid and not has_exclude:
                send_to_discord(title, link, prefix)
    except Exception as e:
        print(f"æŠ“å–å¤±æ•—: {e}")

if __name__ == "__main__":
    print("--- å•Ÿå‹•çµ‚æ¥µç²¾æº–ç›£æ¸¬ç³»çµ± ---")
    
    # 1. å°ç£æœ¬åœ°æœå°‹
    tw_url = "https://news.google.com/rss/search?q=ç«ç½+OR+çˆ†ç‚¸+OR+ç«è­¦+when:1h&hl=zh-TW&gl=TW&ceid=TW:zh-tw"
    fetch_and_filter(tw_url, "ğŸ‡¹ğŸ‡¼ **å°ç£å³æ™‚ç«è­¦**")
    
    # 2. å…¨çƒä¸­æ–‡æœå°‹ (åŠ å¼·ç‰ˆï¼šæœå°‹å…¨çƒæ–°èä½†è¦æ±‚ Google æä¾›ä¸­æ–‡æ¨™é¡Œ)
    # ä½¿ç”¨ç•¶å‰æ™‚é–“ 1 å°æ™‚å…§çš„æ–°è
    global_url = "https://news.google.com/rss/search?q=Fire+OR+Explosion+when:1h&hl=zh-TW&gl=TW&ceid=TW:zh-tw"
    fetch_and_filter(global_url, "ğŸŒ **å…¨çƒé‡å¤§è­¦å ±**")
    
    print("--- ç›£æ¸¬çµæŸ ---")
