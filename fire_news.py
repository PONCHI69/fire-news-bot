import requests
from bs4 import BeautifulSoup
import hashlib
import os
from datetime import datetime, timedelta

# =========================
# åŸºæœ¬è¨­å®šèˆ‡é—œéµå­—
# =========================
DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK")
SEEN_FILE = "seen_events.txt"

FIRE_KEYWORDS = [
    "fire", "blaze", "ç«ç½", "ç«è­¦", "èµ·ç«", "ç‡’æ¯€", "æ•‘ç½",
    "é‹°é›»æ± ", "å¤ªé™½èƒ½", "å„²èƒ½", "å¤±ç«"
]

EXPLOSION_KEYWORDS = ["explosion", "çˆ†ç‚¸", "æ°£çˆ†", "å™´å‡º", "æ´©æ¼"]

FACILITY_KEYWORDS = [
    "factory", "plant", "mill", "refinery", "warehouse",
    "å·¥å» ", "å» æˆ¿", "å€‰å„²", "å·¥æ¥­", "åŒ–å·¥", "çŸ³åŒ–", "ç…‰æ²¹",
    "ç§‘æŠ€", "é›»å­", "é›»å» ", "åœ’å€", "ä¸­æ²¹", "å°å¡‘"
]

EXCLUDE_KEYWORDS = [
    "éŠæˆ²", "steam", "é™å…", "æ¨¡æ“¬", "å¤§äº¨","æ¼”ç·´",
    "ç¼ºå·¥", "é—œç¨…", "è‚¡å¸‚", "è¬›åº§", "è«–å£‡",
    "å…§é–£", "é¸èˆ‰", "ç ”è¨æœƒ", "ç‡Ÿæ”¶", "æˆ¿å¸‚"
]

HEADERS = {"User-Agent": "Mozilla/5.0"}

# =========================
# å»é‡è™•ç†
# =========================
def _event_key(title, link):
    return hashlib.sha256(f"{title}{link}".encode("utf-8")).hexdigest()

def is_duplicate(title, link):
    if not os.path.exists(SEEN_FILE):
        return False
    key = _event_key(title, link)
    with open(SEEN_FILE, "r") as f:
        return key in f.read().splitlines()

def save_event(title, link):
    key = _event_key(title, link)
    with open(SEEN_FILE, "a") as f:
        f.write(key + "\n")

# =========================
# åˆ¤æ–·é‚è¼¯
# =========================
def check_match(title):
    t = title.lower()
    has_event = any(k in t for k in FIRE_KEYWORDS + EXPLOSION_KEYWORDS)
    has_place = any(k in t for k in FACILITY_KEYWORDS)
    has_exclude = any(k in t for k in EXCLUDE_KEYWORDS)
    return has_event and has_place and not has_exclude

def get_severity(title):
    t = title.lower()
    if any(k in t for k in ["æ­»", "killed", "dead", "fatal"]):
        return "ğŸš¨ é‡å¤§å‚·äº¡"
    if any(k in t for k in ["å‚·", "injured"]):
        return "âš ï¸ æœ‰äººå—å‚·"
    if any(k in t for k in EXPLOSION_KEYWORDS):
        return "ğŸ’¥ ç™¼ç”Ÿçˆ†ç‚¸"
    return "ğŸ”¥ ç«è­¦é€šå ±"

def parse_time(date_str):
    try:
        gmt_time = datetime.strptime(
            date_str, "%a, %d %b %Y %H:%M:%S %Z"
        )
        tw_time = gmt_time + timedelta(hours=8)
        return tw_time.strftime("%Y-%m-%d %H:%M")
    except Exception:
        return "æœªçŸ¥æ™‚é–“"

# =========================
# ä¸»ç¨‹å¼
# =========================
def run_monitor():
    urls = [
        (
            'https://news.google.com/rss/search?q='
            '(å·¥å» +OR+å» æˆ¿+OR+çŸ³åŒ–+OR+å·¥æ¥­å€+OR+åŒ–å·¥+OR+ç§‘æŠ€+OR+é›»å­)'
            '+(ç«ç½+OR+çˆ†ç‚¸+OR+ç«è­¦+OR+èµ·ç«)+when:24h'
            '&hl=zh-TW&gl=TW&ceid=TW:zh-tw',
            "ğŸ­ å·¥æ¥­/å·¥å» æƒ…å ±"
        ),
        (
            'https://news.google.com/rss/search?q='
            '(factory+OR+industrial+OR+refinery)'
            '+(fire+OR+explosion)+when:24h'
            '&hl=en-US&gl=US&ceid=US:en',
            "ğŸŒ å…¨çƒå·¥æ¥­è­¦å ±"
        )
    ]

    for rss_url, prefix in urls:
        try:
            res = requests.get(rss_url, headers=HEADERS, timeout=15)
            soup = BeautifulSoup(res.content, features="xml")
            items = soup.find_all("item")

            for item in items[:15]:
                title = item.title.text.strip()
                link = item.link.text.strip()
                pub_date = item.pubDate.text if item.pubDate else ""
                tw_time = parse_time(pub_date)

                if not check_match(title):
                    continue
                if is_duplicate(title, link):
                    continue

                severity = get_severity(title)

                message = (
                    f"{prefix}\n"
                    f"**ã€{severity}ã€‘**\n"
                    f"[{title}](<{link}>)\n"
                    f"ğŸ•’ åŸå§‹ç™¼å¸ƒæ™‚é–“ (TW): `{tw_time}`"
                )

                print(message)

                if DISCORD_WEBHOOK_URL:
                    requests.post(
                        DISCORD_WEBHOOK_URL,
                        json={"content": message},
                        timeout=10
                    )

                save_event(title, link)

        except Exception as e:
            print(f"[ERROR] RSS è®€å–å¤±æ•—: {e}")

# =========================
# é€²å…¥é»
# =========================
if __name__ == "__main__":
    run_monitor()
