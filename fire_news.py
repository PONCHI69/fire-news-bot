import requests
from bs4 import BeautifulSoup
import hashlib
import os
import re
import json
from datetime import datetime, timedelta

# =========================
# é…ç½®
# =========================
WEBHOOK_GENERAL = os.getenv("DISCORD_WEBHOOK_GENERAL")
WEBHOOK_CHEMICAL = os.getenv("DISCORD_WEBHOOK_CHEMICAL")
WEBHOOK_ENERGY = os.getenv("DISCORD_WEBHOOK_ENERGY")

SEEN_FILE = "seen_events.json"
HEADERS = {"User-Agent": "Mozilla/5.0"}

# é—œéµå­—è¨­å®š
FIRE = ["fire", "blaze", "ç«ç½", "ç«è­¦", "èµ·ç«", "å¤±ç«"]
EXPLOSION = ["explosion", "çˆ†ç‚¸", "æ°£çˆ†"]
CHEMICAL = ["chemical", "petrochemical", "refinery", "çŸ³åŒ–", "åŒ–å·¥", "ç…‰æ²¹"]
ENERGY = ["power", "plant", "é›»å» ", "è®Šé›»æ‰€", "å„²èƒ½", "å¤ªé™½èƒ½", "é‹°é›»æ± "]
TECH = ["semiconductor", "electronics", "wafer", "åŠå°é«”", "é›»å­"]
BUILDING = ["building", "apartment", "skyscraper", "å¤§æ¨“", "ä½å®…"]

EXCLUDE = ["æ¼”ç·´", "æ¨¡æ“¬", "æ¼”ç¿’", "è¨“ç·´", "simulation", "drill", "è‚¡å¸‚", "æ”¿ç­–", "èª¿æŸ¥", "åŸå› ä»æœªç¢ºå®š"]

COUNTRY_MAP = {"greece": "ğŸ‡¬ğŸ‡·", "japan": "ğŸ‡¯ğŸ‡µ", "us": "ğŸ‡ºğŸ‡¸", "u.s.": "ğŸ‡ºğŸ‡¸", "uk": "ğŸ‡¬ğŸ‡§", "china": "ğŸ‡¨ğŸ‡³", "taiwan": "ğŸ‡¹ğŸ‡¼"}

# =========================
# å·¥å…·å‡½å¼
# =========================
def load_seen():
    if not os.path.exists(SEEN_FILE): return {}
    try:
        with open(SEEN_FILE, "r", encoding="utf-8") as f: return json.load(f)
    except: return {}

def save_seen(data):
    with open(SEEN_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def translate_to_zh(text):
    try:
        res = requests.get("https://translate.googleapis.com/translate_a/single",
                           params={"client": "gtx", "sl": "auto", "tl": "zh-TW", "dt": "t", "q": text}, timeout=10)
        return res.json()[0][0][0]
    except: return text

def extract_event_core(title):
    """
    å„ªåŒ–å¾Œçš„äº‹ä»¶æ ¸å¿ƒæå–ï¼šå°‡åŒç¾©è©ã€æ­»å‚·äººæ•¸å‰”é™¤ï¼Œå¼·åŒ–å»é‡
    """
    t = title.lower()
    
    # 1. åµæ¸¬ç½å®³é¡å‹
    event_type = "fire" if any(k in t for k in FIRE) else "explosion"
    
    # 2. åµæ¸¬åœ‹å®¶
    location = next((k for k in COUNTRY_MAP.keys() if k in t), "global")
    
    # 3. è¨­æ–½æ­£è¦åŒ– (å°‡ cookie å’Œ biscuit åˆä½µ)
    t = t.replace("cookie", "biscuit")
    facility_keywords = ["refinery", "biscuit", "factory", "plant", "semiconductor", "warehouse", "å·¥å» ", "å» æˆ¿", "é¤…ä¹¾", "ç…‰æ²¹å» "]
    facility = next((k for k in facility_keywords if k in t), "industrial_site")
    
    # 4. ç§»é™¤æ¨™é¡Œä¸­çš„è®Šå‹•æ•¸å­— (æ­»å‚·äººæ•¸)
    t = re.sub(r"\d+", "", t)
    
    # ç”¢ç”Ÿç©©å®šçš„æŒ‡ç´‹
    return hashlib.sha256(f"{location}-{facility}-{event_type}".encode()).hexdigest()

def detect_country(text):
    t = text.lower()
    for k, flag in COUNTRY_MAP.items():
        if k in t: return flag
    return "ğŸŒ"

# =========================
# æ ¸å¿ƒåŸ·è¡Œ
# =========================
def run_realtime():
    seen_events = load_seen()
    feeds = [
        "https://news.google.com/rss/search?q=(factory+OR+industrial+OR+refinery)+(fire+OR+explosion)+when:12h&hl=en&gl=US&ceid=US:en",
        "https://news.google.com/rss/search?q=(å·¥å» +OR+å» æˆ¿+OR+é£Ÿå“å» )+(ç«ç½+OR+çˆ†ç‚¸)+when:12h&hl=zh-TW&gl=TW&ceid=TW:zh-tw",
    ]

    event_pool = {}
    now = datetime.now()

    for url in feeds:
        try:
            res = requests.get(url, headers=HEADERS, timeout=15)
            soup = BeautifulSoup(res.content, "xml")
            for item in soup.find_all("item")[:40]:
                title = item.title.text
                if any(k in title.lower() for k in EXCLUDE): continue
                if not any(k in title.lower() for k in FIRE + EXPLOSION): continue

                fp = extract_event_core(title)
                
                # è·¨æ¬¡å»é‡
                if fp in seen_events: continue

                if fp not in event_pool:
                    event_pool[fp] = {
                        "titles": [title], 
                        "link": item.link.text, 
                        "pub": item.pubDate.text,
                        "origin_title": title # ç”¨æ–¼ç¿»è­¯åˆ¤å®š
                    }
                else:
                    # é¿å…åŒæ¨™é¡Œé‡è¤‡åŠ å…¥
                    if title not in event_pool[fp]["titles"]:
                        event_pool[fp]["titles"].append(title)
                        
        except Exception as e: print(f"RSS éŒ¯èª¤: {e}")

    sent_count = 0
    for fp, data in event_pool.items():
        # é¸æ“‡é•·åº¦ä¸­ç­‰çš„æ¨™é¡Œä½œç‚ºä¸»æ¨™é¡Œï¼Œé€šå¸¸è¼ƒæº–ç¢º
        main_title = sorted(data["titles"], key=len)[len(data["titles"])//2]
        flag = detect_country(main_title)
        
        # ç¿»è­¯é‚è¼¯
        display_title = f"{main_title}\nï¼ˆ{translate_to_zh(main_title)}ï¼‰" if flag != "ğŸ‡¹ğŸ‡¼" else main_title
        
        msg = (
            f"{flag} **å…¨çƒå·¥æ¥­äº‹æ•…é€šå ±**\n"
            f"[{display_title}](<{data['link']}>)\n"
            f"ğŸ§  æ­¤äº‹ä»¶å·²æ•´åˆ `{len(data['titles'])}` å‰‡æ–°èä¾†æº\n"
            f"ğŸ•’ æ™‚é–“ï¼š`{data['pub']}`"
        )
        
        requests.post(WEBHOOK_GENERAL, json={"content": msg}, timeout=10)
        seen_events[fp] = now.isoformat()
        sent_count += 1

    if sent_count == 0:
        requests.post(WEBHOOK_GENERAL, json={"content": "âœ… **ç³»çµ±ç›£æ¸¬æ­£å¸¸**\néå» 12 å°æ™‚å…§ç„¡æ–°å¢å·¥æ¥­äº‹æ•…æ–°èã€‚"})

    save_seen(seen_events)

if __name__ == "__main__":
    run_realtime()
