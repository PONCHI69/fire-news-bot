import requests
from bs4 import BeautifulSoup
import hashlib
import os
from datetime import datetime, timedelta

# =========================
# åŸºæœ¬è¨­å®š
# =========================
DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK")
SEEN_FILE = "seen_events.txt"
HEADERS = {"User-Agent": "Mozilla/5.0"}

# æ“´å……åœ°é»èˆ‡äº‹æ•…è©å½™
FIRE_KEYWORDS = ["fire", "blaze", "ç«ç½", "ç«è­¦", "èµ·ç«", "ç‡’æ¯€", "æ•‘ç½", "é‹°é›»æ± ", "å¤ªé™½èƒ½", "å„²èƒ½", "å¤±ç«"]
EXPLOSION_KEYWORDS = ["explosion", "çˆ†ç‚¸", "æ°£çˆ†", "æ´©æ¼", "å™´å‡º"]
FACILITY_KEYWORDS = [
    "factory", "plant", "mill", "refinery", "warehouse", "å·¥å» ", "å» æˆ¿", "å€‰å„²", "å·¥æ¥­", 
    "åŒ–å·¥", "çŸ³åŒ–", "ç…‰æ²¹", "ç§‘æŠ€", "é›»å­", "é›»å» ", "åœ’å€", "ä¸­æ²¹", "å°å¡‘", "å» ", 
    "è®Šé›»", "æ²¹åº«", "è®Šå£“å™¨", "æ–½å·¥", "ç¾å ´", "æ§½", "ç®¡"
]
EXCLUDE_KEYWORDS = ["éŠæˆ²", "steam", "æ¨¡æ“¬å™¨", "å¤§äº¨", "ç¼ºå·¥", "é—œç¨…", "è‚¡å¸‚", "è¬›åº§", "è«–å£‡", "ç ”è¨æœƒ", "ç‡Ÿæ”¶", "æˆ¿å¸‚", "æ¼”ç·´", "æ¨¡æ“¬"]

# =========================
# é‚è¼¯æ¨¡çµ„ (ç¶­æŒ GPT å„ªåŒ–æ¶æ§‹)
# =========================
def event_key(title, link):
    return hashlib.sha256(f"{title}{link}".encode("utf-8")).hexdigest()

def is_duplicate(title, link):
    if not os.path.exists(SEEN_FILE): return False
    with open(SEEN_FILE, "r") as f:
        return event_key(title, link) in f.read().splitlines()

def save_event(title, link):
    with open(SEEN_FILE, "a") as f:
        f.write(event_key(title, link) + "\n")

def check_match(title):
    t = title.lower()
    if any(k in t for k in EXCLUDE_KEYWORDS): return False
    has_event = any(k in t for k in FIRE_KEYWORDS + EXPLOSION_KEYWORDS)
    has_place = any(k in t for k in FACILITY_KEYWORDS)
    return has_event and has_place

def get_severity(title):
    t = title.lower()
    if any(k in t for k in ["dead", "killed", "fatal", "æ­»äº¡", "èº«äº¡"]): return "ğŸš¨ é‡å¤§å‚·äº¡"
    if any(k in t for k in ["injured", "å—å‚·"]): return "âš ï¸ æœ‰äººå—å‚·"
    if any(k in t for k in EXPLOSION_KEYWORDS): return "ğŸ’¥ ç™¼ç”Ÿçˆ†ç‚¸"
    return "ğŸ”¥ ç«è­¦é€šå ±"

def parse_time(date_str):
    try:
        gmt = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z')
        tw = gmt + timedelta(hours=8)
        return tw.strftime('%Y-%m-%d %H:%M')
    except:
        return "æœªçŸ¥æ™‚é–“"

def translate_to_zh(text):
    try:
        res = requests.get("https://translate.googleapis.com/translate_a/single",
                           params={"client": "gtx", "sl": "en", "tl": "zh-TW", "dt": "t", "q": text}, timeout=10)
        return res.json()[0][0][0]
    except:
        return "ï¼ˆç¿»è­¯å¤±æ•—ï¼‰"

# =========================
# åŸ·è¡Œä¸»ç¨‹å¼ (å„ªåŒ– URL)
# =========================
def run_monitor():
    # ä¿®æ­£ when:24h ä½ç½®ï¼Œä¸¦å¼·åŒ–æœå°‹èªæ³•
    urls = [
        ("https://news.google.com/rss/search?q=(å·¥å» +OR+å» æˆ¿+OR+çŸ³åŒ–+OR+å·¥æ¥­å€+OR+ä¸­æ²¹+OR+è®Šé›»æ‰€)+after:1d+(ç«ç½+OR+çˆ†ç‚¸+OR+ç«è­¦)&hl=zh-TW&gl=TW&ceid=TW:zh-tw", "ğŸ­ å·¥æ¥­/å·¥å» æƒ…å ±"),
        ("https://news.google.com/rss/search?q=(factory+OR+industrial+OR+refinery)+after:1d+(fire+OR+explosion)&hl=zh-TW&gl=TW&ceid=TW:zh-tw", "ğŸŒ å…¨çƒå·¥æ¥­è­¦å ±")
    ]

    for rss_url, prefix in urls:
        try:
            res = requests.get(rss_url, headers=HEADERS, timeout=15)
            soup = BeautifulSoup(res.content, features="xml")
            # å¢åŠ æƒææ·±åº¦è‡³ 20 å‰‡ï¼Œé¿å…è¢«èˆŠèæ“‹ä½æ–°è¨Š
            for item in soup.find_all('item')[:20]:
                title = item.title.text
                link = item.link.text
                pub_date = item.pubDate.text if item.pubDate else ""
                tw_time = parse_time(pub_date)

                if check_match(title) and not is_duplicate(title, link):
                    severity = get_severity(title)
                    display_title = title
                    if prefix == "ğŸŒ å…¨çƒå·¥æ¥­è­¦å ±":
                        translated = translate_to_zh(title)
                        display_title = f"{title}\nğŸ“ ç¿»è­¯: {translated}"
                    
                    message = (
                        f"{prefix}\n"
                        f"**ã€{severity}ã€‘**\n"
                        f"[{display_title}](<{link}>)\n"
                        f"ğŸ•’ åŸå§‹ç™¼å¸ƒæ™‚é–“ (TW): `{tw_time}`"
                    )
                    
                    requests.post(DISCORD_WEBHOOK_URL, json={"content": message})
                    save_event(title, link)
        except Exception as e:
            print(f"éŒ¯èª¤: {e}")

if __name__ == "__main__":
    run_monitor()
