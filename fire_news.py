import requests
from bs4 import BeautifulSoup
import hashlib
import os
from datetime import datetime, timedelta
import sys

# =========================
# åŸºæœ¬è¨­å®š
# =========================
DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK")
SEEN_FILE = "seen_events.txt"
HEADERS = {"User-Agent": "Mozilla/5.0"}

# =========================
# é—œéµå­—è¨­å®š
# =========================
FIRE_KEYWORDS = [
    "fire", "blaze", "ç«ç½", "ç«è­¦", "èµ·ç«", "ç‡’æ¯€", "å¤±ç«", "æ•‘ç½",
    "é‹°é›»æ± ", "å¤ªé™½èƒ½", "å„²èƒ½"
]

EXPLOSION_KEYWORDS = [
    "explosion", "çˆ†ç‚¸", "æ°£çˆ†", "æ´©æ¼", "å™´å‡º"
]

FACILITY_KEYWORDS = [
    "factory", "plant", "mill", "refinery", "warehouse",
    "å·¥å» ", "å» æˆ¿", "å€‰å„²", "å·¥æ¥­", "å» ", "å€‰åº«",
    "å…¬å¸", "ç§‘æŠ€", "é›»å­", "åœ’å€", "ä½œæ¥­",
    "åŒ–å·¥", "çŸ³åŒ–", "ç…‰æ²¹", "æ²¹åº«", "é›»å» ",
    "ä¸­æ²¹", "å°å¡‘", "è®Šé›»æ‰€", "å¤§æ¨“"
]

EXCLUDE_KEYWORDS = [
    "æ¼”ç·´", "æ¨¡æ“¬", "æ¼”ç¿’", "è¨“ç·´", "å®£å°", "é é˜²",
    "simulation", "drill", "exercise",
    "éŠæˆ²", "steam", "æ¨¡æ“¬å™¨",
    "è‚¡å¸‚", "ç‡Ÿæ”¶", "æˆ¿å¸‚", "è«–å£‡", "è¬›åº§", "ç ”è¨æœƒ",
    "æ´»å‹•"
]

# =========================
# å·¥å…·å‡½å¼
# =========================
def ensure_seen_file():
    if not os.path.exists(SEEN_FILE):
        open(SEEN_FILE, "w").close()

def event_key(title, link):
    return hashlib.sha256(f"{title}{link}".encode("utf-8")).hexdigest()

def is_duplicate(title, link):
    ensure_seen_file()
    with open(SEEN_FILE, "r") as f:
        return event_key(title, link) in f.read().splitlines()

def save_event(title, link):
    ensure_seen_file()
    with open(SEEN_FILE, "a") as f:
        f.write(event_key(title, link) + "\n")

def check_match(title, is_global=False):
    t = title.lower()

    if any(k.lower() in t for k in EXCLUDE_KEYWORDS):
        return False

    has_event = any(k.lower() in t for k in FIRE_KEYWORDS + EXPLOSION_KEYWORDS)
    if not has_event:
        return False

    if is_global:
        return True

    return any(k.lower() in t for k in FACILITY_KEYWORDS)

def get_severity(title):
    t = title.lower()
    if any(k in t for k in ["dead", "killed", "fatal", "æ­»äº¡", "èº«äº¡"]):
        return "ğŸš¨ é‡å¤§å‚·äº¡"
    if any(k in t for k in ["injured", "å—å‚·"]):
        return "âš ï¸ æœ‰äººå—å‚·"
    if any(k in t for k in EXPLOSION_KEYWORDS):
        return "ğŸ’¥ ç™¼ç”Ÿçˆ†ç‚¸"
    return "ğŸ”¥ ç«è­¦é€šå ±"

def parse_time(date_str):
    try:
        gmt = datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %Z")
        tw = gmt + timedelta(hours=8)
        return tw.strftime("%Y-%m-%d %H:%M")
    except Exception:
        return "æœªçŸ¥æ™‚é–“"

def translate_to_zh(text):
    try:
        res = requests.get(
            "https://translate.googleapis.com/translate_a/single",
            params={
                "client": "gtx",
                "sl": "auto",
                "tl": "zh-TW",
                "dt": "t",
                "q": text
            },
            timeout=10
        )
        return res.json()[0][0][0]
    except Exception:
        return "ï¼ˆç¿»è­¯å¤±æ•—ï¼‰"

def send_to_discord(message):
    if not DISCORD_WEBHOOK_URL:
        print("âŒ æœªè¨­å®š DISCORD_WEBHOOKï¼Œå·²ç•¥éç™¼é€")
        return
    requests.post(DISCORD_WEBHOOK_URL, json={"content": message}, timeout=10)

# =========================
# ä¸»æµç¨‹
# =========================
def run_monitor():
    if not DISCORD_WEBHOOK_URL:
        print("âš ï¸ è­¦å‘Šï¼šæœªè¨­å®š DISCORD_WEBHOOKï¼Œåƒ…é¡¯ç¤º log")

    feeds = [
        (
            "https://news.google.com/rss/search?q=(å·¥å» +OR+å» æˆ¿+OR+å·¥æ¥­å€+OR+åŒ–å·¥+OR+ç§‘æŠ€+OR+é›»å­)+(ç«ç½+OR+çˆ†ç‚¸+OR+ç«è­¦+OR+èµ·ç«)+when:12h&hl=zh-TW&gl=TW&ceid=TW:zh-tw",
            "ğŸ­ å·¥å» æƒ…å ±",
            False
        ),
        (
            "https://news.google.com/rss/search?q=(factory+OR+industrial+OR+refinery)+(fire+OR+explosion)+when:12h&hl=en&gl=US&ceid=US:en",
            "ğŸŒ å…¨çƒå·¥æ¥­äº‹æ•…",
            True
        )
    ]

    for rss_url, prefix, is_global in feeds:
        print(f"ğŸ” æŠ“å–ï¼š{prefix}")
        try:
            res = requests.get(rss_url, headers=HEADERS, timeout=15)
            soup = BeautifulSoup(res.content, "xml")

            for item in soup.find_all("item")[:20]:
                title = item.title.text.strip()
                link = item.link.text.strip()
                pub_date = item.pubDate.text if item.pubDate else ""

                if not check_match(title, is_global):
                    continue
                if is_duplicate(title, link):
                    continue

                severity = get_severity(title)
                time_str = parse_time(pub_date)

                display_title = title
                if is_global:
                    display_title += f"\nğŸ“ ç¿»è­¯ï¼š{translate_to_zh(title)}"

                message = (
                    f"{prefix}\n"
                    f"**ã€{severity}ã€‘**\n"
                    f"[{display_title}](<{link}>)\n"
                    f"ğŸ•’ åŸå§‹ç™¼å¸ƒæ™‚é–“ (TW)ï¼š`{time_str}`"
                )

                send_to_discord(message)
                save_event(title, link)
                print(f"âœ… å·²é€šå ±ï¼š{title}")

        except Exception as e:
            print(f"âŒ æŠ“å–å¤±æ•—ï¼š{e}")

# =========================
# å…¥å£
# =========================
if __name__ == "__main__":
    run_monitor()
