import requests
from bs4 import BeautifulSoup
import hashlib
import os
import re
import json
from datetime import datetime, timedelta

# =========================
# é…ç½®
# =========================
WEBHOOK_GENERAL = os.getenv("DISCORD_WEBHOOK_GENERAL")
WEBHOOK_CHEMICAL = os.getenv("DISCORD_WEBHOOK_CHEMICAL")
WEBHOOK_ENERGY = os.getenv("DISCORD_WEBHOOK_ENERGY")

SEEN_FILE = "seen_events.json"
HEADERS = {"User-Agent": "Mozilla/5.0"}

# =========================
# é—œéµå­—è¨­å®š
# =========================
FIRE = ["fire", "blaze", "ç«ç½", "ç«è­¦", "èµ·ç«", "å¤±ç«", "å¤§ç«", "å»¶ç‡’", "ç‡’æ¯€"]
EXPLOSION = ["explosion", "çˆ†ç‚¸", "æ°£çˆ†", "çˆ†ç‡ƒ"]

CHEMICAL = ["chemical", "petrochemical", "refinery", "çŸ³åŒ–", "åŒ–å·¥", "ç…‰æ²¹"]
ENERGY = ["power", "plant", "é›»å» ", "è®Šé›»æ‰€", "å„²èƒ½", "å¤ªé™½èƒ½", "é‹°é›»æ± "]
TECH = ["semiconductor", "electronics", "wafer", "åŠå°é«”", "é›»å­"]
BUILDING = ["building", "apartment", "skyscraper", "å¤§æ¨“", "ä½å®…", "å…¬å¯“", "æ°‘å®…", "ç¤¾å€", "neighborhood", "home", "house"]

# å¼·åŒ–æ’é™¤ï¼šéæ¿¾è¡Œæ”¿ã€æ³•å¾‹ã€è¶¨å‹¢ã€éç¾å ´æ–°è
EXCLUDE = [
    "æ¼”ç·´", "æ¨¡æ“¬", "æ¼”ç¿’", "è¨“ç·´", "simulation", "drill", "exercise", "training",
    "è‚¡å¸‚", "æ”¿ç­–", "èª¿æŸ¥", "å§”å“¡æœƒ", "å ±å‘Š", "åŸå› ä»æœªç¢ºå®š", "èµ·ç«æˆå› ", "å®£å°", 
    "housing", "æˆ¿å±‹", "å¹³å®‰ç¬¦", "é»ç‡ƒå¸‚å ´", "é»ç‡ƒè˜‹æœ", "order", "executive", "è¡Œæ”¿å‘½ä»¤", "æ‰¹å‡†", "æ³•æ¡ˆ"
]

FIRE_METAPHOR = ["under fire", "firestorm", "fiery debate", "political fire", "fire back"]

REAL_FIRE_CONTEXT = [
    "caught fire", "on fire", "burned", "burnt", "fire broke out", "fire erupted",
    "exploded", "blast", "detonated", "massive fire", "destroyed"
]

FACILITY_KEYWORDS = [
    "factory", "plant", "refinery", "warehouse", "home", "house", "residential",
    "å·¥å» ", "å» æˆ¿", "ç…‰æ²¹å» ", "é£Ÿå“å» ", "é¤…ä¹¾", "æ°‘å®…", "ä½å®…", "ç¤¾å€", "nursery"
]

COUNTRY_MAP = {
    "greece": "ğŸ‡¬ğŸ‡·", "japan": "ğŸ‡¯ğŸ‡µ", "us": "ğŸ‡ºğŸ‡¸", "u.s.": "ğŸ‡ºğŸ‡¸", "america": "ğŸ‡ºğŸ‡¸",
    "uk": "ğŸ‡¬ğŸ‡§", "germany": "ğŸ‡©ğŸ‡ª", "china": "ğŸ‡¨ğŸ‡³", "taiwan": "ğŸ‡¹ğŸ‡¼", "brazil": "ğŸ‡§ğŸ‡·",
    "norway": "ğŸ‡³ğŸ‡´", "trikala": "ğŸ‡¬ğŸ‡·"
}

# =========================
# å·¥å…·å‡½å¼
# =========================
def load_seen():
    if not os.path.exists(SEEN_FILE): return {}
    try:
        with open(SEEN_FILE, "r", encoding="utf-8") as f: return json.load(f)
    except: return {}

def save_seen(data):
    with open(SEEN_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def translate_to_zh(text):
    try:
        res = requests.get(
            "https://translate.googleapis.com/translate_a/single",
            params={"client": "gtx", "sl": "auto", "tl": "zh-TW", "dt": "t", "q": text},
            timeout=10,
        )
        return res.json()[0][0][0]
    except: return text

def detect_country(text):
    t = text.lower()
    for k, flag in COUNTRY_MAP.items():
        if k in t: return flag
    return "ğŸŒ"

def classify_channel(title):
    t = title.lower()
    if any(k in t for k in CHEMICAL): return "CHEMICAL"
    if any(k in t for k in ENERGY): return "ENERGY"
    if any(k in t for k in TECH): return "TECH"
    if any(k in t for k in BUILDING): return "BUILDING"
    return "GENERAL"

def webhook_by_channel(ch):
    mapping = {"CHEMICAL": WEBHOOK_CHEMICAL, "ENERGY": WEBHOOK_ENERGY, "TECH": WEBHOOK_GENERAL, "BUILDING": WEBHOOK_GENERAL}
    return mapping.get(ch, WEBHOOK_GENERAL)

def detect_casualties(titles):
    combined_text = " ".join(titles).lower()
    if re.search(r"(\d+ (dead|kill|die|injure|victim)|(\d+)äºº(æ­»|å‚·|äº¡|å‘½))", combined_text):
        return "ğŸš¨ "
    return ""

def is_real_incident(title: str) -> bool:
    t = title.lower()
    if any(p in t for p in FIRE_METAPHOR): return False
    if any(k in t for k in EXCLUDE): return False
    has_event_word = any(k in t for k in FIRE + EXPLOSION)
    has_facility = any(k in t for k in FACILITY_KEYWORDS)
    has_real_context = (
        any(k in t for k in REAL_FIRE_CONTEXT)
        or any(k in t for k in ["ç«ç½", "èµ·ç«", "å¤±ç«", "çˆ†ç‚¸", "æ°£çˆ†", "ç‡’æ¯€", "ç«è­¦"])
    )
    return has_event_word and has_facility and has_real_context

def extract_event_fingerprint(title):
    """æå–äº‹æ•…æŒ‡ç´‹ï¼šç§»é™¤æ•¸å­—èˆ‡å™ªéŸ³ï¼Œå¼·åŒ–è·¨æ¬¡å»é‡"""
    t = title.lower()
    # ç§»é™¤æ¨™é¡Œçµå°¾çš„åª’é«”åç¨± (é€šå¸¸åœ¨æœ€å¾Œä¸€å€‹ - æˆ– | ä¹‹å¾Œ)
    t = re.split(r' - | \| ', t)[0]
    location = next((k for k in COUNTRY_MAP.keys() if k in t), "global")
    facility = next((k for k in FACILITY_KEYWORDS if k in t), "site")
    # ç§»é™¤æ‰€æœ‰æ•¸å­—é¿å…æŒ‡ç´‹è®Šå‹•
    t_clean = re.sub(r"\d+", "", t)
    t_clean = re.sub(r"[^a-z\u4e00-\u9fff]", "", t_clean)
    core = f"{location}-{facility}-{t_clean[:10]}"
    return hashlib.sha256(core.encode("utf-8")).hexdigest()

# =========================
# ä¸»æµç¨‹
# =========================
def run_realtime():
    seen_events = load_seen()
    now = datetime.now()
    event_pool = {}

    feeds = [
        "https://news.google.com/rss/search?q=(factory+OR+industrial+OR+refinery)+(fire+OR+explosion)+when:12h&hl=en&gl=US&ceid=US:en",
        "https://news.google.com/rss/search?q=(å·¥å» +OR+å» æˆ¿+OR+é£Ÿå“å» )+(ç«ç½+OR+çˆ†ç‚¸)+when:12h&hl=zh-TW&gl=TW&ceid=TW:zh-tw",
        "https://news.google.com/rss/search?q=(fire+OR+blaze)+(massive+OR+destroyed+OR+homes)+when:12h&hl=en&gl=US&ceid=US:en"
    ]

    for url in feeds:
        try:
            res = requests.get(url, headers=HEADERS, timeout=15)
            soup = BeautifulSoup(res.content, "xml")
            for item in soup.find_all("item")[:40]:
                title = item.title.text
                if not is_real_incident(title): continue

                fp = extract_event_fingerprint(title)
                # è·¨æ¬¡å»é‡ï¼šå¦‚æœæª”æ¡ˆè£¡å·²ç¶“æœ‰é€™çµ„æŒ‡ç´‹ï¼Œä»£è¡¨ä¹‹å‰ç™¼éäº†
                if fp in seen_events: continue

                if fp not in event_pool:
                    event_pool[fp] = {
                        "titles": [title],
                        "link": item.link.text,
                        "pub": item.pubDate.text if item.pubDate else "",
                    }
                else:
                    if title not in event_pool[fp]["titles"]:
                        event_pool[fp]["titles"].append(title)
        except Exception as e:
            print(f"RSS éŒ¯èª¤: {e}")

    sent = 0
    for fp, data in event_pool.items():
        main_title_raw = data["titles"][0]
        # éæ¿¾ä¸»æ¨™é¡Œå°¾éƒ¨åª’é«”å
        main_title = re.split(r' - | \| ', main_title_raw)[0]
        
        alert_prefix = detect_casualties(data["titles"])
        flag = detect_country(main_title)
        channel = classify_channel(main_title)
        webhook = webhook_by_channel(channel)

        is_chinese = bool(re.search(r"[\u4e00-\u9fff]", main_title))
        display_title = (
            main_title if is_chinese 
            else f"{main_title}\nï¼ˆ{translate_to_zh(main_title)}ï¼‰"
        )

        # ç›¸é—œå ±å°ç™½å­—é‚è¼¯ï¼šç§»é™¤èˆ‡ä¸»æ¨™é¡Œå¤ªç›¸ä¼¼çš„é …ç›®
        others = []
        main_norm = re.sub(r"[^a-zA-Z\u4e00-\u9fff]", "", main_title).lower()
        for t in data["titles"][1:5]:
            t_clean = re.split(r' - | \| ', t)[0]
            t_norm = re.sub(r"[^a-zA-Z\u4e00-\u9fff]", "", t_clean).lower()
            # å¦‚æœæ¨™é¡Œé‡åˆåº¦ä¸é«˜æ‰é¡¯ç¤º
            if t_norm[:20] != main_norm[:20]:
                others.append(t_clean)

        source_info = f"\n\nğŸ”— **ç›¸é—œå ±å°**ï¼š\n" + "\n".join([f"â€¢ {t[:50]}..." for t in others]) if others else ""

        msg = (
            f"{alert_prefix}{flag} **å…¨çƒé‡å¤§ç½æƒ…é€šå ±**\n"
            f"ğŸ”¥ åˆ†é¡ï¼š`{channel}`\n"
            f"[{display_title}](<{data['link']}>)\n"
            f"ğŸ§  æœ¬æ¬¡æƒæå·²æ•´åˆ `{len(data['titles'])}` å‰‡ä¾†æº{source_info}\n"
            f"ğŸ•’ æ™‚é–“ï¼š`{data['pub']}`"
        )

        requests.post(webhook, json={"content": msg}, timeout=10)
        seen_events[fp] = now.isoformat()
        sent += 1

    # ä¿®æ­£å¿ƒè·³é‚è¼¯ï¼šå¦‚æœæƒæå®Œç•¢å®Œå…¨æ²’æœ‰ã€Œæ–°æŒ‡ç´‹ã€æ‰ç™¼é€
    if sent == 0:
        requests.post(
            WEBHOOK_GENERAL,
            json={"content": "âœ… **ç³»çµ±ç›£æ¸¬æ­£å¸¸**\nç³»çµ±è¨­å®šçš„å‰ 12 å€‹å°æ™‚å…§ï¼Œç„¡æ–°å¢é‡å¤§ç½æƒ…æ–°èã€‚"},
            timeout=10,
        )

    save_seen(seen_events)

if __name__ == "__main__":
    run_realtime()
