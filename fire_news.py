import requests
from bs4 import BeautifulSoup
import hashlib
import os
import re
import json
from datetime import datetime, timedelta

# =========================
# é…ç½®
# =========================
WEBHOOK_GENERAL = os.getenv("DISCORD_WEBHOOK_GENERAL")
WEBHOOK_CHEMICAL = os.getenv("DISCORD_WEBHOOK_CHEMICAL")
WEBHOOK_ENERGY = os.getenv("DISCORD_WEBHOOK_ENERGY")

SEEN_FILE = "seen_events.json"
HEADERS = {"User-Agent": "Mozilla/5.0"}

# =========================
# é—œéµå­—è¨­å®š
# =========================
FIRE = ["fire", "blaze", "ç«ç½", "ç«è­¦", "èµ·ç«", "å¤±ç«", "å¤§ç«", "å»¶ç‡’", "ç‡’æ¯€"]
EXPLOSION = ["explosion", "çˆ†ç‚¸", "æ°£çˆ†", "çˆ†ç‡ƒ"]

CHEMICAL = ["chemical", "petrochemical", "refinery", "çŸ³åŒ–", "åŒ–å·¥", "ç…‰æ²¹"]
ENERGY = ["power", "plant", "é›»å» ", "è®Šé›»æ‰€", "å„²èƒ½", "å¤ªé™½èƒ½", "é‹°é›»æ± "]
TECH = ["semiconductor", "electronics", "wafer", "åŠå°é«”", "é›»å­"]
# æ“´å……ï¼šåŠ å…¥å¤§è¦æ¨¡æ°‘å®…ç›¸é—œè©å½™
BUILDING = ["building", "apartment", "skyscraper", "å¤§æ¨“", "ä½å®…", "å…¬å¯“", "æ°‘å®…", "ç¤¾å€", "neighborhood"]

# æ’é™¤é›œè¨Š
EXCLUDE = [
    "æ¼”ç·´", "æ¨¡æ“¬", "æ¼”ç¿’", "è¨“ç·´", "simulation", "drill", "exercise", "training",
    "è‚¡å¸‚", "æ”¿ç­–", "èª¿æŸ¥", "å§”å“¡æœƒ", "å ±å‘Š", "åŸå› ä»æœªç¢ºå®š", "èµ·ç«æˆå› ", "å®£å°", 
    "housing", "æˆ¿å±‹", "å¹³å®‰ç¬¦", "é»ç‡ƒå¸‚å ´", "é»ç‡ƒè˜‹æœ"
]

FIRE_METAPHOR = ["under fire", "firestorm", "fiery debate", "political fire", "fire back"]

REAL_FIRE_CONTEXT = [
    "caught fire", "on fire", "burned", "burnt", "fire broke out", "fire erupted",
    "exploded", "blast", "detonated", "massive fire", "destroyed"
]

# æ“´å……ï¼šåŠ å…¥æ°‘å®…è¨­æ–½é—œéµå­—
FACILITY_KEYWORDS = [
    "factory", "plant", "refinery", "warehouse", "home", "house", "residential",
    "å·¥å» ", "å» æˆ¿", "ç…‰æ²¹å» ", "é£Ÿå“å» ", "é¤…ä¹¾", "æ°‘å®…", "ä½å®…", "ç¤¾å€"
]

COUNTRY_MAP = {
    "greece": "ğŸ‡¬ğŸ‡·", "japan": "ğŸ‡¯ğŸ‡µ", "us": "ğŸ‡ºğŸ‡¸", "u.s.": "ğŸ‡ºğŸ‡¸", "america": "ğŸ‡ºğŸ‡¸",
    "uk": "ğŸ‡¬ğŸ‡§", "germany": "ğŸ‡©ğŸ‡ª", "china": "ğŸ‡¨ğŸ‡³", "taiwan": "ğŸ‡¹ğŸ‡¼", "brazil": "ğŸ‡§ğŸ‡·"
}

# =========================
# å·¥å…·å‡½å¼
# =========================
def load_seen():
    if not os.path.exists(SEEN_FILE): return {}
    try:
        with open(SEEN_FILE, "r", encoding="utf-8") as f: return json.load(f)
    except: return {}

def save_seen(data):
    with open(SEEN_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def translate_to_zh(text):
    try:
        res = requests.get(
            "https://translate.googleapis.com/translate_a/single",
            params={"client": "gtx", "sl": "auto", "tl": "zh-TW", "dt": "t", "q": text},
            timeout=10,
        )
        return res.json()[0][0][0]
    except: return text

def detect_country(text):
    t = text.lower()
    for k, flag in COUNTRY_MAP.items():
        if k in t: return flag
    return "ğŸŒ"

def classify_channel(title):
    t = title.lower()
    if any(k in t for k in CHEMICAL): return "CHEMICAL"
    if any(k in t for k in ENERGY): return "ENERGY"
    if any(k in t for k in TECH): return "TECH"
    if any(k in t for k in BUILDING): return "BUILDING"
    return "GENERAL"

def webhook_by_channel(ch):
    mapping = {"CHEMICAL": WEBHOOK_CHEMICAL, "ENERGY": WEBHOOK_ENERGY, "TECH": WEBHOOK_GENERAL, "BUILDING": WEBHOOK_GENERAL}
    return mapping.get(ch, WEBHOOK_GENERAL)

def detect_casualties(titles):
    """åµæ¸¬æ¨™é¡Œä¸­æ˜¯å¦å«æœ‰å‚·äº¡é—œéµå­—"""
    combined_text = " ".join(titles).lower()
    # åŒ¹é…è‹±æ–‡æ­»å‚·æˆ–ä¸­æ–‡æ­»å‚·
    if re.search(r"(\d+ (dead|kill|die|injure|victim)|(\d+)äºº(æ­»|å‚·|äº¡|å‘½))", combined_text):
        return "ğŸš¨ "
    return ""

# =========================
# äº‹æ•…åˆ¤æ–·èˆ‡æŒ‡ç´‹æå–
# =========================
def is_real_incident(title: str) -> bool:
    t = title.lower()
    if any(p in t for p in FIRE_METAPHOR): return False
    if any(k in t for k in EXCLUDE): return False
    
    has_event_word = any(k in t for k in FIRE + EXPLOSION)
    has_facility = any(k in t for k in FACILITY_KEYWORDS)
    has_real_context = (
        any(k in t for k in REAL_FIRE_CONTEXT)
        or any(k in t for k in ["ç«ç½", "èµ·ç«", "å¤±ç«", "çˆ†ç‚¸", "æ°£çˆ†", "ç‡’æ¯€"])
    )
    return has_event_word and has_facility and has_real_context

def extract_event_fingerprint(title):
    """æå–äº‹æ•…æ ¸å¿ƒç‰¹å¾µï¼ˆç§»é™¤è®Šå‹•æ•¸å­—ä»¥é˜²ç¯„é‡è¤‡é€šå ±ï¼‰"""
    t = title.lower()
    event_type = "fire" if any(k in t for k in FIRE) else "explosion"
    facility = next((k for k in FACILITY_KEYWORDS if k in t), "site")
    location = next((k for k in COUNTRY_MAP.keys() if k in t), "global")
    # æ ¸å¿ƒå„ªåŒ–ï¼šç§»é™¤æ‰€æœ‰æ•¸å­—ï¼Œç¢ºä¿ã€Œ300æ£Ÿæˆ¿å±‹ã€èˆ‡ã€Œ400æ£Ÿæˆ¿å±‹ã€æŒ‡ç´‹ç›¸åŒ
    t_clean = re.sub(r"\d+", "", t)
    core = f"{location}-{facility}-{event_type}"
    return hashlib.sha256(core.encode("utf-8")).hexdigest()

# =========================
# ä¸»æµç¨‹
# =========================
def run_realtime():
    seen_events = load_seen()
    now = datetime.now()

    feeds = [
        # åŸæœ‰å·¥æ¥­æœå°‹
        "https://news.google.com/rss/search?q=(factory+OR+industrial+OR+refinery)+(fire+OR+explosion)+when:12h&hl=en&gl=US&ceid=US:en",
        "https://news.google.com/rss/search?q=(å·¥å» +OR+å» æˆ¿+OR+é£Ÿå“å» )+(ç«ç½+OR+çˆ†ç‚¸)+when:12h&hl=zh-TW&gl=TW&ceid=TW:zh-tw",
        # æ–°å¢ï¼šå¤§è¦æ¨¡ä½å®…ç«ç½æœå°‹
        "https://news.google.com/rss/search?q=(fire+OR+blaze)+(massive+OR+destroyed+OR+homes)+when:12h&hl=en&gl=US&ceid=US:en"
    ]

    event_pool = {}

    for url in feeds:
        try:
            res = requests.get(url, headers=HEADERS, timeout=15)
            soup = BeautifulSoup(res.content, "xml")

            for item in soup.find_all("item")[:40]:
                title = item.title.text
                if not is_real_incident(title): continue

                fp = extract_event_fingerprint(title)
                if fp in seen_events: continue

                if fp not in event_pool:
                    event_pool[fp] = {
                        "titles": [title],
                        "link": item.link.text,
                        "pub": item.pubDate.text if item.pubDate else "",
                    }
                else:
                    if title not in event_pool[fp]["titles"]:
                        event_pool[fp]["titles"].append(title)

        except Exception as e:
            print(f"RSS è®€å–éŒ¯èª¤: {e}")

    sent = 0
    for fp, data in event_pool.items():
        # é¸æ“‡ä¸­é–“é•·åº¦çš„æ¨™é¡Œä½œç‚ºä»£è¡¨
        main_title = sorted(data["titles"], key=len)[len(data["titles"]) // 2]
        
        # åŠŸèƒ½ï¼šåµæ¸¬å‚·äº¡è­¦å ±æ¨™è¨˜
        alert_prefix = detect_casualties(data["titles"])
        
        flag = detect_country(main_title)
        channel = classify_channel(main_title)
        webhook = webhook_by_channel(channel)

        is_chinese = bool(re.search(r"[\u4e00-\u9fff]", main_title))
        display_title = (
            main_title if is_chinese 
            else f"{main_title}\nï¼ˆ{translate_to_zh(main_title)}ï¼‰"
        )

        # åŠŸèƒ½ï¼šç”¢ç”Ÿå¤šä¾†æºç°¡åŒ–æ¸…å–® (é¡¯ç¤ºå‰3å‰‡)
        others = data["titles"][1:4]
        source_list = "\n".join([f"â€¢ {t[:40]}..." for t in others])
        source_info = f"\n\nğŸ”— **ç›¸é—œå ±å°**ï¼š\n{source_list}" if others else ""

        msg = (
            f"{alert_prefix}{flag} **å…¨çƒé‡å¤§ç½æƒ…é€šå ±**\n"
            f"ğŸ”¥ åˆ†é¡ï¼š`{channel}`\n"
            f"[{display_title}](<{data['link']}>)\n"
            f"ğŸ§  æœ¬æ¬¡æƒæå·²æ•´åˆ `{len(data['titles'])}` å‰‡ä¾†æº{source_info}\n"
            f"ğŸ•’ æ™‚é–“ï¼š`{data['pub']}`"
        )

        requests.post(webhook, json={"content": msg}, timeout=10)
        seen_events[fp] = now.isoformat()
        sent += 1

    if sent == 0:
        requests.post(
            WEBHOOK_GENERAL,
            json={"content": "âœ… **ç³»çµ±ç›£æ¸¬æ­£å¸¸**\nç³»çµ±è¨­å®šçš„å‰ 12 å€‹å°æ™‚å…§ï¼Œç„¡æ–°å¢é‡å¤§ç½æƒ…æ–°èã€‚"},
            timeout=10,
        )

    save_seen(seen_events)

if __name__ == "__main__":
    run_realtime()
