import requests
from bs4 import BeautifulSoup
import hashlib
import os

# =========================
# åŸºæœ¬è¨­å®šèˆ‡é—œéµå­—
# =========================
DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK")
SEEN_FILE = "seen_events.txt"  # å»ºè­°æ”¹å›æ–‡å­—æª”ï¼Œåœ¨ GitHub Actions å­˜æª”æœ€ç©©å®š

FIRE_KEYWORDS = ["fire", "blaze", "ç«ç½", "ç«è­¦", "èµ·ç«", "ç‡’æ¯€","æ•‘ç½","é‹°é›»æ± ","å¤ªé™½èƒ½","å„²èƒ½","å¤±ç«"]
EXPLOSION_KEYWORDS = ["explosion", "çˆ†ç‚¸", "æ°£çˆ†","å™´å‡º","æ´©æ¼"]
FACILITY_KEYWORDS = ["factory", "plant", "mill", "refinery", "warehouse", "å·¥å» ", "å» æˆ¿", "å€‰å„²", "å·¥æ¥­", "å…¬å¸", "ç§‘æŠ€", "é›»å­", "å» ","å€‰åº«","åœ’å€","ä¸­å¿ƒ","ä½œæ¥­","ç¾å ´","æ§½","ç®¡"]
EXCLUDE_KEYWORDS = ["éŠæˆ²", "steam", "é™å…", "æ¨¡æ“¬å™¨", "å¤§äº¨", "ç¼ºå·¥", "é—œç¨…", "è‚¡å¸‚", "è¬›åº§", "è«–å£‡","å…§é–£","é¸","é‡‘æ­£æ©","ç ”è¨æœƒ","ç‡Ÿæ”¶","æˆ¿å¸‚"]

# =========================
# é‚è¼¯æ¨¡çµ„
# =========================
def is_duplicate(title, link):
    key = hashlib.sha256(f"{title}{link}".encode("utf-8")).hexdigest()
    if not os.path.exists(SEEN_FILE):
        return False
    with open(SEEN_FILE, "r") as f:
        seen = f.read().splitlines()
    return key in seen

def save_event(title, link):
    key = hashlib.sha256(f"{title}{link}".encode("utf-8")).hexdigest()
    with open(SEEN_FILE, "a") as f:
        f.write(key + "\n")

def check_match(title):
    t = title.lower()
    # å¿…é ˆåŒ…å« (ç«ç½ æˆ– çˆ†ç‚¸) ä¸” å¿…é ˆåŒ…å« (è¨­æ–½åœ°é») ä¸” ä¸èƒ½æœ‰ (é»‘åå–®)
    has_event = any(k in t for k in FIRE_KEYWORDS + EXPLOSION_KEYWORDS)
    has_place = any(k in t for k in FACILITY_KEYWORDS)
    has_exclude = any(k in t for k in EXCLUDE_KEYWORDS)
    return has_event and has_place and not has_exclude

def get_severity(title):
    # ç°¡å–®åˆ¤æ–·åš´é‡ç¨‹åº¦
    if any(k in title for k in ["æ­»", "killed", "dead", "fatal"]): return "ğŸš¨ é‡å¤§å‚·äº¡"
    if any(k in title for k in ["å‚·", "injured"]): return "âš ï¸ æœ‰äººå—å‚·"
    if any(k in title for k in EXPLOSION_KEYWORDS): return "ğŸ’¥ ç™¼ç”Ÿçˆ†ç‚¸"
    return "ğŸ”¥ ç«è­¦é€šå ±"

# =========================
# åŸ·è¡Œä¸»ç¨‹å¼
# =========================
def run_monitor():
    urls = [
        ("https://news.google.com/rss/search?q=\"å·¥å» \"+(ç«ç½+OR+çˆ†ç‚¸+OR+ç«è­¦)+when:24h&hl=zh-TW&gl=TW&ceid=TW:zh-tw", "ğŸ­ å·¥æ¥­/å·¥å» æƒ…å ±"),
        ("https://news.google.com/rss/search?q=(\"factory\"+OR+\"industrial\")+(fire+OR+explosion)+when:24h&hl=zh-TW&gl=TW&ceid=TW:zh-tw", "ğŸŒ å…¨çƒå·¥æ¥­è­¦å ±")
    ]

    for rss_url, prefix in urls:
        try:
            res = requests.get(rss_url, headers={"User-Agent": "Mozilla/5.0"})
            soup = BeautifulSoup(res.content, features="xml")
            for item in soup.find_all('item')[:10]:
                title = item.title.text
                link = item.link.text
                
                if check_match(title) and not is_duplicate(title, link):
                    severity = get_severity(title)
                    # çµ„åˆè¨Šæ¯
                    message = f"{prefix}\n**ã€{severity}ã€‘**\n[{title}](<{link}>)"
                    requests.post(DISCORD_WEBHOOK_URL, json={"content": message})
                    save_event(title, link)
        except Exception as e:
            print(f"éŒ¯èª¤: {e}")

if __name__ == "__main__":
    run_monitor()
